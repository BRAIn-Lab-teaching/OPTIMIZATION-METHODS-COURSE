{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "SP8_Qwjp4jwy",
   "metadata": {
    "id": "SP8_Qwjp4jwy"
   },
   "source": [
    "## Домашнее задание 4, Ускорение и оптимальные методы\n",
    "### Deadline -  11.10.2024    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c63021",
   "metadata": {
    "id": "e4c63021"
   },
   "source": [
    "## Основная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cLNzAhdr9ws7",
   "metadata": {
    "id": "cLNzAhdr9ws7"
   },
   "source": [
    "Рассмотрим задачу минимизации эмпирического риска:\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{x \\in \\mathbb{R}^d} \\left[ f(x) = \\frac{1}{n} \\sum\\limits_{i=1}^n \\ell_x(a_i, b_i) + \\frac{\\lambda}{2} \\| x \\|^2_2\\right],\n",
    "\\end{equation}\n",
    "\n",
    "где:\n",
    "- $\\ell_x(a_i, b_i)$ — функция потерь (cross-entropy loss),\n",
    "- $x$ — вектор параметров модели,\n",
    "- $\\{a_i, b_i\\}_{i=1}^n$ — выборка данных,\n",
    "- $\\lambda > 0$ — параметр регуляризации.\n",
    "\n",
    "Функция потерь для каждого объекта $i$ записывается как:\n",
    "\n",
    "\\begin{equation}\n",
    "\\ell_x(a_i, b_i) = -b_i \\ln(p(x^Ta_i)) - (1 - b_i) \\ln(1 - p(x^Ta_i)),\n",
    "\\end{equation}\n",
    "\n",
    "где $p(x^Ta_i)$ — это вероятность, вычисляемая с помощью логистической функции в комбинации с линейной моделью:\n",
    "\n",
    "\\begin{equation}\n",
    "p(x^Ta_i) = \\frac{1}{1 + \\exp(-x^T a_i)}.\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cRjeUJtXkKvp",
   "metadata": {
    "id": "cRjeUJtXkKvp"
   },
   "source": [
    "Подробнее почитать можно [здесь](https://habr.com/ru/articles/485872/) и [здесь](https://habr.com/ru/articles/803397/). Разобраться глубже можно [вот здесь](https://web.stanford.edu/~jurafsky/slp3/5.pdf), например."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P-mFLYM-0udG",
   "metadata": {
    "id": "P-mFLYM-0udG"
   },
   "source": [
    "__Задача 1. (всего 4 балла)__ Проведем подготовительную работу.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-RbXPgCC_QtD",
   "metadata": {
    "id": "-RbXPgCC_QtD"
   },
   "source": [
    "__а). (2 балла)__ Исследуем задачу на сильную выпуклость и липшицевость."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0KG_4cwlVE6b",
   "metadata": {
    "id": "0KG_4cwlVE6b"
   },
   "source": [
    "Докажите, что градиент нашей функции потерь равен:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla f(x) = \\frac{1}{n} \\sum_{i=1}^n (p(x^Ta_i) - b_i) a_i + \\lambda x\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fZp7YJApVHR1",
   "metadata": {
    "id": "fZp7YJApVHR1"
   },
   "source": [
    "__Ваше решение__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WFf0ooKhVHjt",
   "metadata": {
    "id": "WFf0ooKhVHjt"
   },
   "source": [
    "\n",
    "\n",
    "Докажите, что гессиан нашей функции потерь равен:\n",
    "\n",
    "\\begin{equation}\n",
    "H(x) = \\frac{1}{n} \\sum_{i=1}^n \\big(p(x^Ta_i)(1 - p(x^Ta_i))\\big) a_i a_i^T + \\lambda I,\n",
    "\\end{equation}\n",
    "\n",
    "где $I$ — это единичная матрица.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o6tX4wYhVJWG",
   "metadata": {
    "id": "o6tX4wYhVJWG"
   },
   "source": [
    "__Ваше решение__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uBV68wSnVLTC",
   "metadata": {
    "id": "uBV68wSnVLTC"
   },
   "source": [
    "Докажите, что константа Липшица градиента $L$ может быть оценена как:\n",
    "\n",
    "\\begin{equation}\n",
    "L = \\frac{1}{4n} \\lambda_{\\max}(A^T A) + \\lambda,\n",
    "\\end{equation}\n",
    "\n",
    "где $A$ — матрица, составленная из строк $a_i^{T}$.\n",
    "\n",
    "при доказательстве используйте, что она равна $\\lambda_{\\max}(H(x))$ (Теорема 2.1.6, стр. 87, [Методы\n",
    "выпуклой оптимизации Ю. Е. Нестеров](https://old.mipt.ru/dcam/upload/abb/nesterovfinal-arpgzk47dcy.pdf)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0FpZsprzVOeK",
   "metadata": {
    "id": "0FpZsprzVOeK"
   },
   "source": [
    "__Ваше решение__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oqTWDcCoVOqI",
   "metadata": {
    "id": "oqTWDcCoVOqI"
   },
   "source": [
    "\n",
    "Теперь покажите, что задача $\\mu$-сильно выпуклая, где $\\mu = \\lambda$. Для этого достаточно показать, что минимальное собственное значение $H(w)$ больше $\\lambda$ (Теорема 6.9, стр. 83, [Пособие](https://docs.yandex.ru/docs/view?url=ya-disk-public%3A%2F%2Fm9Htnh7F1wdW0MvhwL7AM4Z%2BzV%2FxsfJcEhRKSH8USLEzt3CIS9ukbzpBKfErQBxmq%2FJ6bpmRyOJonT3VoXnDag%3D%3D%3A%2F%D0%9F%D0%BE%D1%81%D0%BE%D0%B1%D0%B8%D0%B5.pdf&name=%D0%9F%D0%BE%D1%81%D0%BE%D0%B1%D0%B8%D0%B5.pdf&nosw=1)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9mgd8hruVVMD",
   "metadata": {
    "id": "9mgd8hruVVMD"
   },
   "source": [
    "__Ваше решение__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61362fe",
   "metadata": {
    "id": "a61362fe"
   },
   "source": [
    "К заданию приложен датасет _mushrooms_. С помощью следующего кода сформируем матрицу $A$ и вектор $b$, в которой и будет храниться выборка $\\{a_i, b_i\\}_{i=1}^n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4a066",
   "metadata": {
    "id": "41f4a066"
   },
   "outputs": [],
   "source": [
    "#файл должен лежать в той же деректории, что и notebook\n",
    "dataset = \"mushrooms.txt\"\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "data = load_svmlight_file(dataset)\n",
    "A, b = data[0].toarray(), data[1]\n",
    "\n",
    "b = b-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fabb63a",
   "metadata": {
    "id": "0fabb63a"
   },
   "source": [
    "Разделим данные на две части: обучающую и тестовую.\n",
    "\n",
    "__Важно:__ обязательно дальше при решении задания для обучения используйте train выборку, а для проверки test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9fd42",
   "metadata": {
    "id": "c8e9fd42"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "A_train, A_test, b_train, b_test = train_test_split(A, b, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GDeQRhedPVQE",
   "metadata": {
    "id": "GDeQRhedPVQE"
   },
   "source": [
    "Зафиксируем seed для воспроизводимости. Для генерации случайных точек используйте созданный генератор `rng` ([документация](https://numpy.org/doc/stable/reference/random/generator.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UwNDGh8sPTm3",
   "metadata": {
    "id": "UwNDGh8sPTm3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d427e",
   "metadata": {
    "id": "082d427e"
   },
   "source": [
    "__б). (0.5 балла)__ Для обучающей части $A_{train}$, $b_{train}$ оцените константу $L$. Задайте $\\lambda$ так, чтобы $\\lambda \\approx L / 1000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec184b82",
   "metadata": {
    "id": "ec184b82"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ps-zoXis1BYc",
   "metadata": {
    "id": "ps-zoXis1BYc"
   },
   "source": [
    "__в). (1.5 балла)__ Реализуйте в коде подсчет значения и градиента для нашей целевой функции. При этом $A$, $b$, $\\lambda$ необходимо подавать в качестве параметра, чтобы была возможность их менять.\n",
    "\n",
    "Настоятельно рекомендуем использовать для этого только библиотеку ``numpy``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J7iZylFDZFzI",
   "metadata": {
    "id": "J7iZylFDZFzI"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d566",
   "metadata": {
    "id": "2377d566"
   },
   "source": [
    "__Задача 2. (всего 6 баллов)__ Моментумом и ускорение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9824b33",
   "metadata": {
    "id": "a9824b33"
   },
   "source": [
    "__a). (0.5 балла)__ Реализуйте метод тяжелого шарика.\n",
    "\n",
    "**Псевдокод алгоритма**\n",
    "\n",
    "_Инициализация:_\n",
    "\n",
    "Величина шага $\\{ \\gamma_k \\}_{k=0} > 0$, моментумы $\\{ \\tau_k \\}_{k=0} \\in [0; 1]$, стартовая точка $ x^0 = x^{-1} \\in \\mathbb{R}^d $, количество итераций $ K $\n",
    "\n",
    "_$k$-ая итерация:_\n",
    "1. Подсчитать направление спуска $$ \\nabla f(x^k) $$\n",
    "2. Сделать шаг алгоритма $$ x^{k+1} = x^k - \\gamma_k \\nabla f(x^k) + \\tau_k (x^k - x^{k-1}) $$\n",
    "\n",
    "Используйте предложенную функцию для реализации алгоритма и допишите недостающие фрагменты. После чего для проверки правильности загрузите функцию в [контест](https://contest.yandex.ru/contest/66540/enter/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f87f42",
   "metadata": {
    "id": "a2f87f42"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "def HeavyBall(grad, criterion, x_0, eps, max_iter, **params):\n",
    "\n",
    "    '''\n",
    "       grad(x) - функция, которая считает градиент целевой функции;\n",
    "       criterion(x) - функция, которая считает критерий;\n",
    "       x_0 - начальная точка;\n",
    "       eps - точность сходимости (обычно 1e-8);\n",
    "       max_iter - количество итераций;\n",
    "       **params - содержит именнованные гиперпараметры метода:\n",
    "           params['gamma'](k) - шаг, зависящий от номера итерации,\n",
    "           params['tau'](k) - моментум, зависящий от номера итерации.\n",
    "    '''\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    x_k = np.copy(x_0)\n",
    "    x_k_prev = np.copy(x_0)\n",
    "    err_x_0 = criterion(x_k)\n",
    "    errors.append(criterion(x_k) / err_x_0)\n",
    "    for k in trange(max_iter):\n",
    "\n",
    "        # Ваше решение\n",
    "\n",
    "        errors.append(criterion(x_k) / err_x_0)\n",
    "        if errors[-1] < eps:\n",
    "            break\n",
    "\n",
    "    return x_k, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340639c7",
   "metadata": {
    "id": "340639c7"
   },
   "source": [
    "__б). (1.5 балла)__ Решите задачу логистической регрессии с помощью метода тяжелого шарика на обучающей выборке.\n",
    "\n",
    "- Используйте шаг $\\frac{1}{L}$\n",
    "- Рассмотрите моментум `tau_0` = $\\frac{\\sqrt{L} - \\sqrt{\\mu}}{\\sqrt{L} + \\sqrt{\\mu}}$ и несколько моментумов в его окрестности\n",
    "- Рассмотрите моментумы равные  $\\frac{k}{k+3}$, $\\frac{k}{k+2}$, $\\frac{k}{k+1}$ ($k$ — номер итерации),\n",
    "- Стартовая точка $x^0$ — случайная, одинаковая для всего задания\n",
    "- Критерий $\\frac{\\| \\nabla f(x^k) \\|}{\\| \\nabla f(x^0) \\|}$\n",
    "\n",
    "Постройте график сходимости метода на тренировочной выборке от числа итераций для различных значений моментума.\n",
    "\n",
    "По оси абцисс — номер итерации, по оси ординат — логарифм значения критерия на этой итерации.\n",
    "\n",
    "Разместите данные для различных моментумов на одном графике, укажите их в легенде.\n",
    "\n",
    "_Следите за оформлением графиков: размер графика, масштаб осей (обычный или логарифмический), подписи осей (в том числе размер), легенда (если на графике не одна линия), толщина линий и т.д. Графики должны быть удобны для чтения._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85ecd3",
   "metadata": {
    "id": "ca85ecd3"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "teyNHibl6xJN",
   "metadata": {
    "id": "teyNHibl6xJN"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (график)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mcFX_3ki9HE5",
   "metadata": {
    "id": "mcFX_3ki9HE5"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (лучшее значение параметра)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9d450",
   "metadata": {
    "id": "41a9d450"
   },
   "source": [
    "__в). (0.5 балла)__ Постройте график сходимости на тестовой выборке от числа итераций.\n",
    "\n",
    "- Используйте шаг $\\frac{1}{L}$\n",
    "- Значения моментума — лучшее из предыдущего пункта\n",
    "- Стартовая точка $x^0$ — случайная, одинаковая для всего задания\n",
    "- Критерий $\\frac{\\| \\nabla f(x^k) \\|}{\\| \\nabla f(x^0) \\|}$\n",
    "\n",
    "\n",
    "\n",
    "По оси абцисс — номер итерации, по оси ординат — логарифм значения критерия на этой итерации.\n",
    "\n",
    "Добавьте на этот же график сходимость градиентного спуска с шагом $\\frac{1}{L}$, укажите обе сходимости в легенде.\n",
    "\n",
    "_Следите за оформлением графиков: размер графика, масштаб осей (обычный или логарифмический), подписи осей (в том числе размер), легенда (если на графике не одна линия), толщина линий и т.д. Графики должны быть удобны для чтения._\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942eda2e",
   "metadata": {
    "id": "942eda2e"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RDAovkCa9etn",
   "metadata": {
    "id": "RDAovkCa9etn"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (график)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595ab14",
   "metadata": {
    "id": "b595ab14"
   },
   "source": [
    "__г). (0.5 балла)__ Реализуйте ускоренный градиентный метод\n",
    "\n",
    "**Псевдокод алгоритма**\n",
    "\n",
    "_Инициализация:_\n",
    "\n",
    "Величина шага $ \\{ \\gamma_k \\}_{k=0} > 0 $, моментум $ \\{ \\tau_k \\}_{k=0} \\in [0; 1] $, стартовая точка $ x^0 = y^0 \\in \\mathbb{R}^d $, количество итераций $ K $\n",
    "\n",
    "_$k$-ая итерация:_\n",
    "1. Подсчитать направление спуска $$ \\nabla f(y^k) $$\n",
    "2. Сделать шаг алгоритма $$ x^{k+1} = y^k - \\gamma_k \\nabla f(y^k) $$\n",
    "3. Вычислить новую точку для подсчета градиента на следующем шаге $$ y^{k+1} = x^{k+1} + \\tau_k (x^{k+1} - x^k) $$\n",
    "\n",
    "Используйте предложенную функцию для реализации алгоритма и допишите недостающие фрагменты. После чего для проверки правильности загрузите функцию в [контест](https://contest.yandex.ru/contest/66540/enter/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc318aae",
   "metadata": {
    "id": "cc318aae"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "def NAG(grad, criterion, x_0, eps, max_iter, **params):\n",
    "    '''\n",
    "       grad(x) - функция, которая считает градиент целевой функции;\n",
    "       criterion(x) - функция, которая считает критерий;\n",
    "       x_0 - начальная точка;\n",
    "       eps - точность сходимости (обычно 1e-8);\n",
    "       max_iter - количество итераций;\n",
    "       **params - содержит именнованные гиперпараметры метода:\n",
    "           params['gamma'](k) - шаг, зависящий от номера итерации,\n",
    "           params['tau'](k) - моментум, зависящий от номера итерации.\n",
    "    '''\n",
    "    errors = []\n",
    "\n",
    "    x_k = np.copy(x_0)\n",
    "    y_k = np.copy(x_0)\n",
    "    err_x_0 = criterion(x_k)\n",
    "    errors.append(criterion(x_k) / err_x_0)\n",
    "    delta = np.zeros_like(x_0)\n",
    "\n",
    "    for k in trange(max_iter):\n",
    "\n",
    "        # Ваше решение\n",
    "\n",
    "        errors.append(criterion(x_k) / err_x_0)\n",
    "        if errors[-1] < eps:\n",
    "            break\n",
    "    return x_k, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AEWIYko3cApu",
   "metadata": {
    "id": "AEWIYko3cApu"
   },
   "source": [
    "__д). (1.5 балла)__ Решите задачу логистической регрессии с помощью ускоренного градиентного метода на обучающей выборке.\n",
    "\n",
    "- Используйте шаг $\\frac{1}{L}$\n",
    "- Рассмотрите моментум `tau_0` = $\\frac{\\sqrt{L} - \\sqrt{\\mu}}{\\sqrt{L} + \\sqrt{\\mu}}$ и несколько моментумов в его окрестности\n",
    "- Рассмотрите моментумы равные  $\\frac{k}{k+3}$, $\\frac{k}{k+2}$, $\\frac{k}{k+1}$ ($k$ — номер итерации),\n",
    "- Стартовая точка $x^0$ — случайная, одинаковая для всего задания\n",
    "- Критерий $\\frac{\\| \\nabla f(x^k) \\|}{\\| \\nabla f(x^0) \\|}$\n",
    "\n",
    "Постройте график сходимости метода на тренировочной выборке от числа итераций для различных значений моментума.\n",
    "\n",
    "По оси абцисс — номер итерации, по оси ординат — логарифм значения критерия на этой итерации.\n",
    "\n",
    "Разместите данные для различных моментумов на одном графике, укажите их в легенде, при этом для моментумов, полученных по формулам, обязательно в легенде указывать именно формулу, а для $\\frac{\\sqrt{L} - \\sqrt{\\mu}}{\\sqrt{L} + \\sqrt{\\mu}}$ дополнительно укажите в скобках значение.\n",
    "\n",
    "_Следите за оформлением графиков: размер графика, масштаб осей (обычный или логарифмический), подписи осей (в том числе размер), легенда (если на графике не одна линия), толщина линий и т.д. Графики должны быть удобны для чтения._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723032fd",
   "metadata": {
    "id": "723032fd"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RyNeVP6gAi93",
   "metadata": {
    "id": "RyNeVP6gAi93"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (график)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o8p4oU3_BDgv",
   "metadata": {
    "id": "o8p4oU3_BDgv"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (лучшее значение параметра)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e622eb0",
   "metadata": {
    "id": "3e622eb0"
   },
   "source": [
    "__е). (1.5 балла)__ Постройте график сходимости на тестовой выборке от числа итераций.\n",
    "\n",
    "- Используйте шаг $\\frac{1}{L}$\n",
    "- Значения моментума — лучшее из предыдущего пункта\n",
    "- Стартовая точка $x^0$ — случайная, одинаковая для всего задания\n",
    "- Критерий $\\frac{\\| \\nabla f(x^k) \\|}{\\| \\nabla f(x^0) \\|}$\n",
    "\n",
    "\n",
    "По оси абцисс — номер итерации, по оси ординат — логарифм значения критерия на этой итерации.\n",
    "\n",
    "Добавьте на этот же график сходимости из пункта в), укажите все три сходимости в легенде.\n",
    "\n",
    "_Следите за оформлением графиков: размер графика, масштаб осей (обычный или логарифмический), подписи осей (в том числе размер), легенда (если на графике не одна линия), толщина линий и т.д. Графики должны быть удобны для чтения._\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0034ba8",
   "metadata": {
    "id": "b0034ba8"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qtaLYvbHDUwp",
   "metadata": {
    "id": "qtaLYvbHDUwp"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (график)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cb096",
   "metadata": {
    "id": "351cb096"
   },
   "source": [
    "# Дополнительная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a7ed63",
   "metadata": {
    "id": "a7a7ed63"
   },
   "source": [
    "__Задача 1. (всего 4 балла)__\n",
    "\n",
    "__а). (1 балл)__ Вспомним, что исходная задача регрессии является задачой машинного обучения и с помощью линейной модели $x^T a$ можно предсказывать значения меток $b$. Как использовать итоговую модель для предсказания?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0y3qzvluSncC",
   "metadata": {
    "id": "0y3qzvluSncC"
   },
   "source": [
    "__Ваше решение__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W36x05krgUcG",
   "metadata": {
    "id": "W36x05krgUcG"
   },
   "source": [
    "__б). (0.5 балла)__ Ответив на вопрос, напишите функцию, которая делает предсказания на тестовой выборке $A_{test}$. Сравните с реальными метками $b_{test}$. Количество правильно угаданных меток есть точность/accuracy модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GBP5AVhyga36",
   "metadata": {
    "id": "GBP5AVhyga36"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T09ID1RvgbH8",
   "metadata": {
    "id": "T09ID1RvgbH8"
   },
   "source": [
    "__в). (2.5 балла)__ Сравните метод градиентного спуска, метод тяжелого шарика, ускоренный градиентный метод. Постройте два графика: значение критерия сходимости от номера итерации и точность предсказания от номера итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TACOw8mIgeZd",
   "metadata": {
    "id": "TACOw8mIgeZd"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kRh8XIoPbjyv",
   "metadata": {
    "id": "kRh8XIoPbjyv"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (график)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EiOEgH8YR7sO",
   "metadata": {
    "id": "EiOEgH8YR7sO"
   },
   "source": [
    "__Задача 2. (всего 6 баллов)__ Универсальное ускорение (на основании [статьи](https://arxiv.org/pdf/1506.02186))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R-PqVi4BpT6d",
   "metadata": {
    "id": "R-PqVi4BpT6d"
   },
   "source": [
    "\n",
    "Catalyst (катализатор) — это универсальная техника, которая придумана, чтобы ускорять любые методы, в частности, самый простой вариант, например, ускорить градиентный спуск, но, по факту, может быть подставлен абсолютно любой метод. Суть этого задания — проверить, какой способ ускорения градиентного спуска лучше: универсальный Catalyst или заточенные конкретно под градиентный спуск техники (ускоренный градиентный спуск Нестерова и метод тяжелого шарика).\n",
    "\n",
    "__a). (1 балл)__ Реализуйте схему ускорения Catalyst для градиентного спуска.\n",
    "\n",
    "Основная идея заключается в том, что мы добавляем к целевой функции слагаемое вида $\\frac{\\kappa}{2} \\| x - y_{k-1} \\|^2$, где $\\kappa$ — гиперпараметр, о котором мы поговорим поздее, а $y_k$ — экстраполяция решения \"по инерции\", как мы делали в методах основной части этого задания. Скорость сходимости градиентого спуска, как известно, зависит от, так называемой, обусловленности задачи, а именно $\\frac{L}{\\mu}$. Нетрудно убедиться, (если коротко, поправка к гессиану будет вида $\\kappa I$, из-за чего все его собственные значения увеличатся на $\\kappa$) что у новой целевой функции число обусловленности будет равно  $\\frac{L + \\kappa}{\\mu + \\kappa}$. Чем ближе это число к единице, тем быстрее сходимость. Очевидно, положительный параметр $\\kappa$ увеличивает число обусловленности, и вот, поэтому, теоретическая сходимость становится лучше. С другой стороны, для не сильно выпуклых задач, то есть $\\mu = 0$, параметр $\\kappa$ выступает, в каком-то смысле, в роле регуляризатора, и делает задачу сильно выпуклой.\n",
    "\n",
    "Теперь запишем эту схему для произвольного алгоритма $A$.\n",
    "\n",
    "**Псевдокод алгоритма**\n",
    "\n",
    "_Инициализация:_\n",
    "\n",
    "Начальное приближение $ x_0 \\in \\mathbb{R}^p $, параметры $ \\kappa $ и $ \\alpha_0 $, последовательность $ \\{ \\varepsilon_k \\}_{k \\geq 0} $, метод оптимизации — $A$.\n",
    "\n",
    "Также необходимо задать следующим образом некоторые из параметров: $$ q = \\frac{\\mu}{\\mu + \\kappa}, \\quad y_0 = x_0 $$\n",
    "\n",
    "_$k$-ая итерация:_\n",
    "   1. Найти приближённое решение следующей задачи с использованием метода $A$:\n",
    "   $$\n",
    "   x_k \\approx \\arg \\min_{x \\in \\mathbb{R}^p} \\left\\{ G_k(x) = F(x) + \\frac{\\kappa}{2} \\| x - y_{k-1} \\|^2 \\right\\},\n",
    "   \\quad \\text{т. ч.} \\quad\n",
    "   G_k(x_k) - G^*_k \\leq \\varepsilon_k.\n",
    "   $$\n",
    "   2. Вычислить $ \\alpha_k \\in (0, 1) $ из уравнения:\n",
    "   $$\n",
    "   \\alpha_k^2 = (1 - \\alpha_k) \\alpha_{k-1}^2 + q \\alpha_k .\n",
    "   $$\n",
    "   3. Вычислить:\n",
    "   $$\n",
    "   y_k = x_k + \\beta_k (x_k - x_{k-1}),\n",
    "   \\quad \\text{где} \\quad\n",
    "   \\beta_k = \\frac{\\alpha_{k-1} (1 - \\alpha_{k-1})}{\\alpha_{k-1}^2 + \\alpha_k}.\n",
    "   $$\n",
    "\n",
    "\n",
    "Теперь давайте ускорим с помощью этой схемы градиентный спуск, то есть возьмём его в качестве алгоритма $A$.\n",
    "\n",
    "Используйте предложенную функцию для реализации алгоритма и допишите недостающие фрагменты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SRc0tFgtsOUr",
   "metadata": {
    "id": "SRc0tFgtsOUr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def catalyst_method(method_A, grad, criterion, x_0, eps, max_iter, **params):\n",
    "    '''\n",
    "    grad(x) - функция, которая считает градиент целевой функции;\n",
    "    criterion(x) - функция, которая считает критерий;\n",
    "    x_0 - начальная точка;\n",
    "    eps - точность сходимости;\n",
    "    max_iter - количество итераций;\n",
    "    method_A - оптимизационный метод (например, градиентный спуск);\n",
    "    **params - гиперпараметры метода:\n",
    "        params['kappa'] - параметр регуляризации,\n",
    "        params['alpha_0'] - начальное значение альфа,\n",
    "        params['mu'] - сильно выпуклый параметр задачи,\n",
    "        params['epsilon_k'] - последовательность точностей для задачи.\n",
    "    '''\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    x_k = np.copy(x_0)\n",
    "    y_k = np.copy(x_0)\n",
    "    alpha_k = params['alpha_0']\n",
    "    q = params['mu'] / (params['mu'] + params['kappa'])\n",
    "    beta_k = 0\n",
    "    x_prev = np.copy(x_0)\n",
    "\n",
    "    # Ваше решение\n",
    "\n",
    "    return x_k, errors\n",
    "\n",
    "def catalyst(method_A, kappa, alpha_0, mu, epsilon_k):\n",
    "    def new_method(grad, criterion, x_0, eps, max_iter, **params):\n",
    "        return catalyst_method(\n",
    "            method_A,\n",
    "            grad,\n",
    "            criterion,\n",
    "            x_0,\n",
    "            eps,\n",
    "            max_iter,\n",
    "            kappa=kappa,\n",
    "            alpha_0=alpha_0,\n",
    "            mu=mu,\n",
    "            epsilon_k=epsilon_k,\n",
    "            **params\n",
    "        )\n",
    "      return new_method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TJlidhUbuJBp",
   "metadata": {
    "id": "TJlidhUbuJBp"
   },
   "source": [
    "__Как выбирать константы по теории__\n",
    "\n",
    "В статье утверждается, что для сходимости алгоритма при сильно выпуклой функции нужно выбрать $ \\alpha_0 = \\sqrt{q} $, где $ q = \\mu / (\\mu + \\kappa) $.\n",
    "\n",
    "\n",
    "Для последовательности $ \\varepsilon_k $ рекомендуется использовать:\n",
    "   \\begin{equation}\n",
    "   \\varepsilon_k = \\frac{2}{9}( F(x_0) - F^* )(1 - \\rho)^k\n",
    "   \\end{equation}\n",
    "  Однако  разница $ F(x_0) - F^* $ изначально неизвестна. Если функция $ F $ неотрицательна, можно заменить $F^*$ на 0. Параметр $ \\rho $ рекомендуется $ \\rho < \\sqrt{q} $. Здесь есть свобода выбора $\\rho $, на практике часто берут $ \\rho = 0.9 \\sqrt{q} $.\n",
    "\n",
    "Выбор $ \\alpha_0 = \\sqrt{q} $ сделан для упрощения анализа, но в некоторых случаях могут быть использованы большие значения $ \\alpha_0 $. Из некоторых соображений, можно выбирать $ \\alpha_0 $ так, чтобы выполнялось уравнение $ \\alpha_0^2 + (1 - q)\\alpha_0 - 1 = 0 $.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "is4Cqh08sUfN",
   "metadata": {
    "id": "is4Cqh08sUfN"
   },
   "source": [
    "\n",
    "\n",
    "__б). (2 балла)__ Решите задачу логистической регрессии с помощью метода Catalyst на обучающей выборке.\n",
    "\n",
    "- Используйте шаг $ \\frac{1}{L} $\n",
    "- Зафиксируйте $\\rho$, $\\alpha$\n",
    "- Рассмотрите 5 различных значений параметра $ \\kappa $\n",
    "- Стартовая точка $x_0$ — точка, у которой все координаты 0\n",
    "- Критерий $ \\frac{\\| \\nabla f(x^k) \\|}{\\| \\nabla f(x^0) \\|} $\n",
    "\n",
    "Постройте график сходимости метода на тренировочной выборке от числа итераций для различных значений параметра $ \\kappa $.\n",
    "\n",
    "По оси абсцисс — номер итерации, по оси ординат — логарифм значения критерия на этой итерации.\n",
    "\n",
    "Разместите данные для различных $ \\kappa $ на одном графике, укажите их в легенде.\n",
    "\n",
    "_Следите за оформлением графиков: размер графика, масштаб осей (обычный или логарифмический), подписи осей (в том числе размер), легенда (если на графике не одна линия), толщина линий и т.д._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FBqMWw4atNO8",
   "metadata": {
    "id": "FBqMWw4atNO8"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7xFT-l6Q1vAG",
   "metadata": {
    "id": "7xFT-l6Q1vAG"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (график)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GxK31X3d2-jE",
   "metadata": {
    "id": "GxK31X3d2-jE"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (лучшее значение параметра)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KsWpNw_EtGyn",
   "metadata": {
    "id": "KsWpNw_EtGyn"
   },
   "source": [
    "\n",
    "__в). (1 балл)__ Постройте график сходимости на тестовой выборке от числа итераций.\n",
    "\n",
    "- Используйте шаг $ \\frac{1}{L} $\n",
    "- Использованные ранее $\\rho$, $\\alpha$\n",
    "- Значение $ \\kappa $ — лучшее из предыдущего пункта\n",
    "- Стартовая точка — случайная, одинаковая для всего задания\n",
    "- Критерий $ \\frac{\\| \\nabla f(x^k) \\|}{\\| \\nabla f(x^0) \\|} $\n",
    "\n",
    "По оси абцисс — номер итерации, по оси ординат — логарифм значения критерия на этой итерации.\n",
    "\n",
    "Добавьте на этот же график сходимости из пункта е) задачи 2, укажите все четыре сходимости в легенде.\n",
    "\n",
    "_Следите за оформлением графиков: размер графика, масштаб осей (обычный или логарифмический), подписи осей (в том числе размер), легенда (если на графике не одна линия), толщина линий и т.д. Графики должны быть удобны для чтения._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYIaqOmIUirV",
   "metadata": {
    "id": "BYIaqOmIUirV"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (график)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yIUGfBawTaUm",
   "metadata": {
    "id": "yIUGfBawTaUm"
   },
   "source": [
    "__г). (2 балла)__ Суперпозиция схем.\n",
    "\n",
    "Проверьте, а что будет, если в качестве $A$ в схеме Catalyst использовать уже ускоренный с помощью данной схемы градиентный спуск. По сути, суперпозиция двух ускорений с помощью схемы Catalyst.\n",
    "\n",
    "Постройте график зависимости точности модели на тестовой выборке от числа итераций.\n",
    "\n",
    "- Используйте шаг $ \\frac{1}{L} $\n",
    "- Использованные ранее $\\rho$, $\\alpha$, лучшее $ \\kappa $\n",
    "- Стартовая точка — случайная, одинаковая для всего задания\n",
    "- Критерий $ \\frac{\\| \\nabla f(x^k) \\|}{\\| \\nabla f(x^0) \\|} $\n",
    "\n",
    "По оси абцисс — номер итерации, по оси ординат — логарифм значения критерия на этой итерации.\n",
    "\n",
    "Добавьте на этот же график сходимость градиентного спуска и сходимость один раз ускоренного с помощью Catalyst.\n",
    "\n",
    "_Следите за оформлением графиков: размер графика, масштаб осей (обычный или логарифмический), подписи осей (в том числе размер), легенда (если на графике не одна линия), толщина линий и т.д. Графики должны быть удобны для чтения._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VpIz1bieTZF2",
   "metadata": {
    "id": "VpIz1bieTZF2"
   },
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkfPqLtfh-d1",
   "metadata": {
    "id": "bkfPqLtfh-d1"
   },
   "outputs": [],
   "source": [
    "# Ваше решение (график)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
