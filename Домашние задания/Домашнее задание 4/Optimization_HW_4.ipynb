{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6fcbb6",
   "metadata": {},
   "source": [
    "# Домашнее задание 4\n",
    "\n",
    "Это домашнее задание по материалам четвертого семинара. Дедлайн по отправке - 23:55 21 марта. \n",
    "\n",
    "Домашнее задание выполняется в этом же Jupyter Notebook'e и присылается на почту: __OptimizationHomework@yandex.ru__.\n",
    "\n",
    "Тема письма для этого домашнего задания: __МФТИ_4__\n",
    "\n",
    "Файл должен называться: __Фамилия_Имя__\n",
    "\n",
    "Решение каждой задачи необходимо поместить после её условия.\n",
    "\n",
    "При полном запуске Вашего решения (Kernel -> Restart & Run All) все ячейки должны выполняться без ошибок."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a8d32",
   "metadata": {},
   "source": [
    "## Задача 1\n",
    "\n",
    "Рассмотрим задачу минимизации эмпирического риска:\n",
    "\\begin{equation}\n",
    "\\min_{w \\in \\mathcal{X} \\subset \\mathbb{R}^d} \\frac{1}{n} \\sum\\limits_{i=1}^n \\ell (g(w, x_i), y_i),\n",
    "\\end{equation}\n",
    "где $\\ell: \\mathbb{R} \\times \\mathbb{R} \\to \\mathbb{R}$ - функция потерь, $g : \\mathbb{R}^d \\times \\mathbb{R}^x \\to \\mathbb{R}$ - модель, $w$ - параметры модели, $\\{x_i, y_i\\}_{i=1}^n$ - выборка данных из векторов признаков $x_i \\in \\mathbb{R}^x$ и меток $y_i \\in \\mathbb{R}$.\n",
    "\n",
    "Используем линейную модель $g(w, x) = w^T x$ и логистическую/сигмоидную функцию потерь: $\\ell(z,y) = \\ln (1 + \\exp(-yz))$ (__Важно: $y$ должен принимать значения $-1$ или $1$__). Полученная задача называется задачей логистической регрессии. \n",
    "\n",
    "В качестве множества $\\mathcal{X}$ возьмем $\\ell_1$-шар с центром в 0 и радиуса $R$ (параметр, которые можно менять): $\\mathcal{X} =\\{x \\in \\mathbb{R}^d \\mid \\| x \\|_1 \\leq R \\}$.\n",
    "\n",
    "__Отличия от прошлых домашных заданий:__ убрали регуляризатор, добавили множество $\\mathcal{X}$.\n",
    "\n",
    "Как и раньше работаем с _mushrooms_ датасетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1340b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mushrooms.txt\" \n",
    "#файл должен лежать в той же деректории, что и notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "data = load_svmlight_file(dataset)\n",
    "X, y = data[0].toarray(), data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87374821",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * y - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44cb05c",
   "metadata": {},
   "source": [
    "Так как мы теперь решаем задачу оптимизации на шаре, необходимы методы, учитывающие это.\n",
    "\n",
    "__(a)__ Для $\\ell_1$-шара с центром в 0 и радиуса $R$ найдите выражение для решения задачи линейной оптимизации при заданном векторе $g \\in \\mathbb{R}^d$:\n",
    "$$\n",
    "s^* = \\arg \\min_{s \\in \\mathcal{X}} \\langle s, g \\rangle.\n",
    "$$\n",
    "\n",
    "Формально обоснуйте свой ответ, например, можно (необязательно именно так) использовать условия ККТ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32864a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f8060",
   "metadata": {},
   "source": [
    "__(б)__ Реализуйте отдельно решение задачи линейной оптимизации из предыдущего пункта (радиус шара $R$ лучше передавать в качестве параметра). Реализуйте метод Франк-Вульфа для нашей задачи. Советую также следующим образом брать шаг в алгоритме: если итерации нумеруются с 0, то $\\gamma = \\frac{2}{k+3}$, если итерации нумеруются с 1, то $\\gamma = \\frac{2}{k+2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40582dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4dc344",
   "metadata": {},
   "source": [
    "__(в)__ Решите задачу оптимизации на обучающей выборке с помощью реализованного методов. Возьмите $R = 5$ и стратовую точку в $0$. В качестве критерия используйте следующее выражение:\n",
    "$$\n",
    "\\text{gap}(w^k) = \\max_{y \\in \\mathcal{X}} \\langle \\nabla f(w^k), w^k - y \\rangle,\n",
    "$$\n",
    "или усредненную версию $\\frac{1}{k} \\sum_{i=1}^k \\text{gap}(w^i)$. Такой критерий используем, так как не знаем значение $f^*$ и не можем гарантировать, что $\\nabla f(w^*) = 0$. Но можно показать, что $\\text{gap}(w^k) \\geq f(w^k) - f^*$, а также доаказать сходимость метода Франк-Вульфа по такому критерию, а значит сходимость по $\\text{gap}(w^k)$ и дает хорошее понимание о поведении $f(w^k) - f^*$.\n",
    "\n",
    "Постройте график сходимости: значение критерия сходимости от номера итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c574a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c1d05",
   "metadata": {},
   "source": [
    "Вывидите решение, полученный с помощью метода Франк-Вульфа. Что необычного увидели? Для большей наглядности можете воспользоваться методом Нестерова из прошлых заданий и решить с помощью него безусловную задачу (на $\\mathbb{R}^d$). Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5780a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a8297",
   "metadata": {},
   "source": [
    "__(г)__ В прошлых заданиях мы, используя полученное решения задачи оптимизации, предсказывали ответы на тестовой выборке. Напомним суть: исходная задача регрессии является задачой машинного обучения и с помощью линейной модели $g$ можно предсказывать значения меток $y$. Пусть у нас есть сэмпл $x_i$, ответ модели для этого сэмпла есть $g(w^*, x^i)$. Тогда предсказывающее правило можно сформулировать следующим довольно естественным образом:\n",
    "$$\n",
    "y_i = \n",
    "\\begin{cases}\n",
    "1, & g(w^*, x^i) \\geq 0,\n",
    "\\\\\n",
    "-1, & g(w^*, x^i) < 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "Cделав предсказания на тестовой выборке $X_{test}$, можно сравните результат с реальными метками $y_{test}$. Количество правильно угаданных меток есть точность/accuracy модели.\n",
    "\n",
    "Посмотрите какую дает модель обученная с помощью метода Франк-Вульфа. Варьируйте $R = 5, 10, 20, 50, 100, 1000$. Постройте три графика: 1) точность итоговой модели от $R$, 2) количество ненулевых компонент в итоговом решении метода Франк-Вульфа от $R$, 3) точность от количества ненулевых компонент в итоговом решении. Сделайте вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37974ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b69b7",
   "metadata": {},
   "source": [
    "__(д)__ Нашу задачу можнно решать и с помощью метода градиентного спуска с евклидовой проекцией. Для этого нужно уметь делать проекцию на $\\ell_1$-шар. Найдите способ сделать проекцию в Интернете, достаточно загуглить: \"projection onto l1 ball\". Изложите здесь суть найденнного подхода (приложите ссылку откуда берете подход) и реализуйте его в коде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fddf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce96d6",
   "metadata": {},
   "source": [
    "Решите задачу оптимизации на обучающей выборке с помощью градиентного спуска с евклидовой проекцией. Сравните на графиках сходимость градиентного спуска и метода Франк-Вульфа: 1) значение критерия от номера итерации, 2) значение критерия от времени. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6902921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56317873",
   "metadata": {},
   "source": [
    "__Бонусные пункты__\n",
    "\n",
    "__(e)__ В [работе](https://arxiv.org/pdf/1511.05932.pdf) представлен способ улучшить работу метода Франк-Вульфа (Алгоритм 1). Кратко объясните идею, которую предлагают авторы. Реализуйте Алгоритм 1 для нашей задачи. Постройте график сходимости по времени и по количеству итераций. Добавьте эти графики к графикам для остальных методов которые были получены выше. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7590aa",
   "metadata": {},
   "source": [
    "__(ж)__ В [работе](https://sci-hub.ru/https://doi.org/10.1137/140992382) представлена ускоренная версия метода Франка-Вульфа (Алгоритм 2 для сильно выпуклой задачи). Он лучше с точки зрения теоретической сходимости по числу вызовов градиента. Реализуйте Алгоритм 2 для нашей задачи. Постройте график сходимости по времени и по количеству подсчетов $\\nabla f$ (для предыдущих методов это было эквивалетно итерациям). Добавьте эти графики к графикам для остальных методов которые были получены выше. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9506cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
