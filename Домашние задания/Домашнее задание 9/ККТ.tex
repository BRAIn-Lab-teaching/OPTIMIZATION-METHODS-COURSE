\begin{center}
    \textbf{Домашнее задание 9, ККТ}
\end{center}

\section*{Основная часть}

\begin{enumerate}[label=\textbf{Задача \arabic*.}]

    \item (2 балла) Рассмотрим задачу о разделении двух подмножеств $\mathbb{R}^d$ гиперплоскостью. Считаем, что  даны точки $x_i \in \mathbb{R}^d$ и метки класса $y_i \in \{-1, 1\}$. Мы хотим построить линейную модель с параметрами $\theta, \theta_0$, для которой 
    \begin{align*}
         x_i^\top \theta + \theta_0 > 0 \quad \Longleftrightarrow \quad y_i > 0
    \end{align*}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\linewidth]{img/Decision-boundary-of-support-vector-machine.png}
    \end{figure}
    Заметим, что наши классы могут быть линейно разделимы с помощью разных гиперплоскостей. Чтобы получить "наилучшую"\   разделяющую гиперплоскость, потребуем более сильное условие
    \begin{align*}
         y_i(x_i^\top \theta + \theta_0) \geq 1
    \end{align*}
    которое означает, чтобы наша линейная модель не просто верно предсказывает знак, но и имеет некоторую степень робастности, т.е. устойчивости к незначительным изменениям признаков. Но проблема с несколькими плоскостями все еще остается -- для любой разделяющей прямой можно раздуть ее коэффициенты, чтобы новое условие выполнялось. Поэтому будем минимизировать $\ell_2$ норму параметра $\theta$:

    \begin{align*}
        \min_{\theta, \theta_0} &~ \frac{1}{2}\|\theta\|_2^2\\
        \text{s.t.} &~ y_i(x_i^\top \theta + \theta_0) \geq 1
    \end{align*}

    Полученная задача подходит для данных, которые полностью линейно отделимы. Теперь перейдем к более общему случаю, для этого ослабим условия, добавив штраф с некоторой константой $\rho$:

    \begin{align*}
        \min_{\theta, \theta_0, \xi} &~ \frac{1}{2}\|\theta\|_2^2 + \rho\sum\limits_{i = 1}^{n}\xi_i\\
        \text{s.t. } \xi_i \geq 0, &~ y_i(x_i^\top \theta + \theta_0) \geq 1 - \xi_i
    \end{align*}

    Выпишите условия ККТ для этой задачи. Выразите параметр $\theta$ через оптимальное решение двойственной задачи. Покажите, что оптимальное решение не изменится, если оставить только точки $x_i$, для которых $y_i(x_i^\top \theta + \theta_0) = 1 - \xi_i$ (\emph{опорные векторы}).

    \item (3 балла) Пусть $f$ -- сильно выпуклая дифференцируемая на $\mathbb{R}^n$ функция, матрица $A \in \mathbb{R}^{n \times d}$ такова, что все ее миноры имеют полный ранг (например, это происходит с вероятностью $1$, если элементы матрицы как случайные величины имеют совместную плотность).
    
    Докажите, что задача с $\ell_1$ регуляризацией 
    \begin{align*}
         \min_{x \in \mathbb{R}^d} \bigg[f(Ax) + \|x\|_1\bigg]
    \end{align*}
    имеет единственное решение, при чем среди его компонент не более $\min(n, d)$ ненулевых.

        
\end{enumerate}


\section*{Дополнительная часть}

\begin{enumerate}[label=\textbf{Задача \arabic*.}]

    \item (5 баллов) Для задачи 
    \begin{align*}
        \min_{X \in \mathbb{S}^n_{++}} & \bigg[\text{tr} X - \text{log det} X\bigg] \\
        \text{s.t. } & Xs = y,
    \end{align*}
    где $\langle s, y \rangle$ = 1, с помощью теоремы о достаточности условий ККТ докажите, что решение задачи единственно и записывается в виде
    \begin{align*}
        X^* = I + yy^\top - \frac{ss^\top}{s^\top s} ~ .
    \end{align*}

\end{enumerate}