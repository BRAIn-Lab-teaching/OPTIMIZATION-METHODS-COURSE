{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6fcbb6",
   "metadata": {},
   "source": [
    "# Домашнее задание 3\n",
    "\n",
    "Это домашнее задание по материалам третьего семинара. Дедлайн по отправке - 23:55 13 марта. \n",
    "\n",
    "Домашнее задание выполняется в этом же Jupyter Notebook'e и присылается на почту: __OptimizationHomework@yandex.ru__.\n",
    "\n",
    "Тема письма для этого домашнего задания: __МФТИ_3__\n",
    "\n",
    "Файл должен называться: __Фамилия_Имя__\n",
    "\n",
    "Решение каждой задачи необходимо поместить после её условия.\n",
    "\n",
    "При полном запуске Вашего решения (Kernel -> Restart & Run All) все ячейки должны выполняться без ошибок."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a8d32",
   "metadata": {},
   "source": [
    "## Задача 1\n",
    "\n",
    "Рассмотрим одномерную задачу минимизации:\n",
    "\\begin{equation}\n",
    "\\min_{x \\in \\mathbb{R}} \\left[f(x) := x \\arctan x - \\frac{1}{2} \\log (1 + x^2)\\right].\n",
    "\\end{equation}\n",
    "\n",
    "__(а)__ Реализуйте для этой задачи метод градиентного спуска и метод Ньютона. Нарисуйте графики сходимости данных методов для двух разных точек старта $x^0 = 1.3$ и $x^0 = 1.5$. Сделайте вывод. В общем случае для каких $x^0$ еще есть сходимость метода Ньютона, а для каких она пропадает? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1340b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb57fe",
   "metadata": {},
   "source": [
    "__(б)__ Реализуйте две модификации метода Ньютона: демпфированный (добавление шага) и кубический метод Ньютона (смотри [статью](https://link.springer.com/article/10.1007/s10107-006-0706-8)). Решают ли эти методы проблему сходимости метода Ньютона для стартовой точки $x^0 = 1.5$? В демпфированном методе попробуйте разные стратегии подбора шага: меняющийся с номером итерации, линейный поиск и другие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d27e1",
   "metadata": {},
   "source": [
    "## Задача 2\n",
    "\n",
    "Вернемся к задаче логистической регресии на датасете _mushrooms_. Добавьте к этой задаче $\\ell_2$-регуляризатор с $\\lambda = L/100$. \n",
    "\n",
    "__(а)__ Для данной задачи реализуйте метод Ньютона и метод градиентного спуска. Попробуйте комбинировать эти два метода, чтобы добиться хорошего решения задачи регрессии, но избежать расходимости метода Ньютона. Как это будете делать? Постройте график сходимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cfdcc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7c504",
   "metadata": {},
   "source": [
    "__(б)__ Для данной задачи реализуйте квазиньютоновские методы: SR1/Бройдена, DFP, BFGS (глава 8 из [книги](https://www.ime.unicamp.br/~pulino/MT404/TextosOnline/NocedalJ.pdf)). Старайтесь их реализовывать эффективно (объясняя, как этого добиваетесь) - кратко мы обсуждали это на семинаре, это есть также в книге выше, а еще [здесь](https://github.com/scipy/scipy/blob/v0.18.1/scipy/optimize/optimize.py#L874-L976). Решите с помощью них задачу регресии. Постройте графики сходимости и изменения accuracy от числа итераций и времени. Сравните с ускоренными методами из прошлого ДЗ. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48c3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0ffdd",
   "metadata": {},
   "source": [
    "__Бонусные пункты__\n",
    "\n",
    "__(в)__ Рассмотрим самый известный и популярный на данный момент квазиньютоновский метод L-BFGS (параграф 9.1 из [книги](http://users.iems.northwestern.edu/~nocedal/PDFfiles/limited-memory.pdf)). Ключ к работе с этим методом его эффетивная реализация. Объясните ключевые особенности вычислений и хранения, которые необходимо учесть, имплементируйте метод, решите с помощью него задачу регресии. Постройте графики сходимости и изменения accuracy от числа итераций и времени. Сравните с методами из пункта (б). Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56317873",
   "metadata": {},
   "source": [
    "__(г)__ Реализуйте подход из [работы](https://pages.cs.wisc.edu/~swright/726/handouts/barzilai-borwein.pdf). С помощью них решите задачу регресии. Сравните их работу с квазиньютоновскими методами. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
