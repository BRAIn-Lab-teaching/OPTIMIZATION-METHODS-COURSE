{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6fcbb6",
   "metadata": {},
   "source": [
    "# Домашнее задание 3\n",
    "\n",
    "Это домашнее задание по материалам второго семинаров. Дедлайн по отправке - 23:55 24 февраля. \n",
    "\n",
    "Домашнее задание выполняется в этом же Jupyter Notebook'e и присылается мне на почту: __beznosikov.an@phystech.edu__.\n",
    "\n",
    "Решение каждой задачи необходимо поместить после её условия.\n",
    "\n",
    "Файл должен называться: Фамилия_Имя_Optimization_HW_3\n",
    "\n",
    "При полном запуске Вашего решения (Kernel -> Restart & Run All) все ячейки должны выполняться без ошибок. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a8d32",
   "metadata": {},
   "source": [
    "## Задача 1\n",
    "\n",
    "Вновь рассмотрим задачу минимизации эмпирического риска:\n",
    "\\begin{equation}\n",
    "\\min_{w \\in \\mathbb{R}^d} \\frac{1}{n} \\sum\\limits_{i=1}^n l (g(w, x_i), y_i).\n",
    "\\end{equation}\n",
    "\n",
    "В прошлом задании работа шла с линейной модель $g(w, x) = w^T x$ и квадратичную функцию потерь $l(z, y) = (z-y)^2$. \n",
    "\n",
    "__(а)__ В дополнение к квадратичной функции потерь реализуйте логистическую/сигмоидную: $l(z,y) = \\ln (1 + \\exp(-yz))$ (__Важно: $y$ должен принимать значения $-1$ или $1$__). Выпишите градиент. Является ли новая задача регресии выпуклой? Оцените $L$ для новой функции потерь. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1340b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb57fe",
   "metadata": {},
   "source": [
    "__(б)__ Возьмите датасет _mushrooms_ из прошлого задания. Проделайте следующие шаги из прошлого задания, только с логистической функцией потерь:\n",
    "\n",
    "1) Разделите данные на две части: обучающую и тестовую.\n",
    "\n",
    "2) Для обучающей части $X_{train}$, $y_{train}$ оцените константу $L$ задачи обучения/оптимизации.\n",
    "\n",
    "3) Используя градиентный спуск, обучите новую модель (без ограничений и регуляризаций). Постройте график: точность от номера итерации.\n",
    "\n",
    "4) Если в пункте 3) пришлось столкнуться с проблемами или просто необходимо улучшить точность, то добавьте ограничения или $\\ell_2$-регуляризацию, как в прошлом ДЗ.\n",
    "\n",
    "5) Сравните с результатами квадратичной функции потерь из прошлого ДЗ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d96a89",
   "metadata": {},
   "source": [
    "## Задача 2\n",
    "\n",
    "__(a)__ Реализуйте метод тяжелого шарика. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd30eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe201d2",
   "metadata": {},
   "source": [
    "__(б)__ Решите задачу логистической регрессии с помощью метода тяжелого шарика (не забудьте разделить выборку на две части: обучающую и тестовую). Зафиксируйте шаг $\\frac{1}{L}$ и перебирайте разные значения моментума от -1 до 1. Постройте график сходимости метода от числа итераций (критерий сходимости подберите самостоятельно) для различных значений моментума. Всегда ли сходимость является монотонной?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40582dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb31fc",
   "metadata": {},
   "source": [
    "__(в)__ Для лучшего значения моментума постройте график зависимости точности модели на тестовой выборке от времени работы метода. Добавьте на этот же график сходимость градиентного спуска с шагом $\\frac{1}{L}$. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9647ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f76c5",
   "metadata": {},
   "source": [
    "__(г)__ Если в пунктах (б) и (в) столкнулись с проблемами, попробуйте $\\ell_2$-регуляризовать задачу или рассмотреть ее на ограниченном множестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7712495",
   "metadata": {},
   "source": [
    "__(д)__ Реализуйте ускоренный метод Нестерова (в форме Нестерова, а не который доказывали на семинаре). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f78fc",
   "metadata": {},
   "source": [
    "__(е)__ Решите задачу логистической регресии с помощью метода Нестерова (не забудьте разделить выборку на две части: обучающую и тестовую). Зафиксируйте шаг $\\frac{1}{L}$ и перебирайте разные значения моментума от -1 до 1. Проверьте также значения моментума равные $\\frac{k}{k+3}$, $\\frac{k}{k+2}$, $\\frac{k}{k+1}$ ($k$ - номер итерации), а если решаете сильно выпуклую задачу, то и $\\frac{\\sqrt{L} - \\sqrt{\\mu}}{\\sqrt{L} + \\sqrt{\\mu}}$. Постройте график сходимости метода от числа итераций (критерий сходимости подберите самостоятельно) для различных значений моментума. Всегда ли сходимость является монотонной?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74034f6",
   "metadata": {},
   "source": [
    "__(ж)__ Для лучшего значения моментума постройте график зависимости точности модели на тестовой выборке от времени работы метода. Добавьте этот график к графикам для тяжелого шарика и градиентного спуска из пункта (г). Сделайте итоговый вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bcfb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56317873",
   "metadata": {},
   "source": [
    "__Бонусные пункт__\n",
    "\n",
    "__(з)__ Сделаем подбор константы $L$ адаптивным. Как упоминалось на семинаре, можно измерять локальную $L$, используя:\n",
    "$$\n",
    "f(y) \\leq f(x^k) + \\langle \\nabla f(x^k), y - x^k \\rangle + \\frac{L}{2}\\|x^k - y\\|_2^2\n",
    "$$\n",
    "В частности, может подойти процедура:\n",
    "\n",
    "```python\n",
    "def backtracking_L(f, grad, x, h, L0, rho):\n",
    "    L = L0\n",
    "    fx = f(x)\n",
    "    gradx = grad(x)\n",
    "    while True:\n",
    "        y = x - 1 / L * h\n",
    "        if f(y) <= fx - 1 / L gradx.dot(h) + 1 / (2 * L) h.dot(h):\n",
    "            break\n",
    "        else:\n",
    "            L = L * rho\n",
    "    return L\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87c7ad",
   "metadata": {},
   "source": [
    "Каким стоит взять __h__? __rho__ должно быть больше или меньше 1? __L0__ надо брать заведомо большим или маленьким?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd9efb5",
   "metadata": {},
   "source": [
    "__(и)__ Поэксперементируйте с этой процедурой, встроенной в подбор $L$ для шага градиентного спуска. В качестве задачи продолжайте рассматривать логистическую регрессию из Задачи 1. Аналогично встройте процедуру подбора $L$ в метод тяжелого шарика и ускоренный метод Нестерова. Постройте график сходимости метода от числа итераций (критерий сходимости подберите самостоятельно). Отобразите на этом графике градиентный спуск, тяжелый шарик и метод Нестерова с адаптивным шагом и шагом $\\frac{1}{L}$ (всего 6 линий на графике). Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d242c4",
   "metadata": {},
   "source": [
    "__(к)__ Постройте аналогичный пункту (и) график точности модели от времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e880742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0ffdd",
   "metadata": {},
   "source": [
    "__(л)__ В [работе](https://arxiv.org/pdf/1204.3982.pdf) представлена техника рестартов для подавления немонотонной сходимости Алгоритма 2 (метод Нестерова). Попробуйте повторить эксперименты авторов на $\\ell_2$-регуляризованной квадратичной или логистической регресии. Возьмите параметр регуляризации $\\lambda = L / 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ответ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
