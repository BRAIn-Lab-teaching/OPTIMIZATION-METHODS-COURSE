{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3a6fa0",
   "metadata": {},
   "source": [
    "# Домашнее задание 1\n",
    "\n",
    "Это домашнее задание по материалам 1-3 недели семестра. Дедлайн по отправке - __23:59 17 марта__.\n",
    "\n",
    "- Домашнее задание выполняется в этом же Jupyter Notebook'e.\n",
    "\n",
    "- Файл необходимо переименовать: __Фамилия_Имя__ (без пробелов в начале и конце). Пример: __Иванов_Иван__.\n",
    "\n",
    "- ДЗ нужно отправлять на __OptimizationHomework@yandex.ru__. Тема письма: __ИАД_номер задания__ (без пробелов в начале и конце). Для данного ДЗ тема письма: __ИАД_1__.\n",
    "\n",
    "- Для решения можно использовать Google Colab, но присылать нужно не ссылку на Colab, а готовый notebook и все необходимые дополнительные файлы.\n",
    "\n",
    "- Решение каждой задачи/пункта задачи поместите после условия.\n",
    "\n",
    "- Не забывайте добавлять необходимые пояснения и комментарии.\n",
    "\n",
    "- В финальной версии, которая будет отправлена на проверку, должны быть удалены все отладочные артефакты. Под таким артефактами подразумеваются любые выводы ячеек, которые никак не прокоментированы в тексте, а также любой массовый/длинный технический вывод (даже если он прокомментирован в тексте).\n",
    "\n",
    "- При полном запуске решения (Kernel -> Restart & Run All) все ячейки должны выполняться без ошибок.\n",
    "\n",
    "- Максимальный балл за задание - 140. Для получения полного балла за домашнее задание необходимо набрать 100 баллов.\n",
    "\n",
    "Желаем успехов!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386bbbb",
   "metadata": {},
   "source": [
    "Рассмотрим задачу минимизации эмпирического риска:\n",
    "\\begin{equation}\n",
    "\\min_{w \\in \\mathbb{R}^d} \\frac{1}{n} \\sum\\limits_{i=1}^n \\ell (g(w, x_i), y_i) + \\frac{\\lambda}{2} \\| w \\|^2_2,\n",
    "\\end{equation}\n",
    "где $\\ell$ - функция потерь, $g$ - модель, $w$ - параметры модели, $\\{x_i, y_i\\}_{i=1}^n$ - выборка данных из векторов признаков $x_i$ и меток $y_i$, $\\lambda > 0$ - параметр регуляризации.\n",
    "\n",
    "Используем линейную модель $g(w, x) = w^T x$ и логистическую/сигмоидную функцию потерь: $\\ell(z,y) = \\ln (1 + \\exp(-yz))$ (__Важно: $y$ должен принимать значения $-1$ или $1$__). Полученная задача называется задачей логистической регрессии. \n",
    "\n",
    "__Задача 1. (всего 20 баллов)__ Проведем подготовительную работу. \n",
    "\n",
    "__а). (15 баллов)__ Покажите, что градиент и гессиан целевой функции можно записать в виде:\n",
    "$$\n",
    "\\nabla f(w) = \\frac{1}{n} \\sum_{i=1}^n \\frac{-y_i}{1 + \\exp(y_i w^Tx_i)}x_i + \\lambda w,\n",
    "\\quad\n",
    "\\nabla^2 f(w) = \\frac{1}{n} \\sum_{i=1}^n \\frac{\\exp(y_i w^Tx_i)}{(1 + \\exp(y_i w^Tx_i))^2} x_i x_i^T + \\lambda I.\n",
    "$$\n",
    "\n",
    "Докажите, что решаемая задача является $\\mu$-сильно выпуклой и имеет $L$-Липшицев градиент с $\\mu = \\lambda$ и $L = \\lambda + \\frac{1}{4n} \\sum_{i=1}^n \\| x_i\\|^2_2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a09e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваше решение (Markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61362fe",
   "metadata": {},
   "source": [
    "К заданию приложен датасет _mushrooms_. С помощью следующего кода сформируйте матрицу $X$ и вектор $y$, в которой и будет храниться выборка $\\{x_i, y_i\\}_{i=1}^n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1f7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mushrooms.txt\" \n",
    "#файл должен лежать в той же деректории, что и notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f4a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "data = load_svmlight_file(dataset)\n",
    "X, y = data[0].toarray(), data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ef9c8",
   "metadata": {},
   "source": [
    "Поменяем вектор $y$, чтобы $y_i$ принимали значения $-1$ и $1$. Вы также можете сделать дополнительную предобработку данных (приемами из машинного обучения), но это никак дополнительно не оценивается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c6af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * y - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fabb63a",
   "metadata": {},
   "source": [
    "Разделим данные на две части: обучающую и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e9fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d427e",
   "metadata": {},
   "source": [
    "__б). (5 балла)__ Для обучающей части $X_{train}$, $y_{train}$ оцените константу $L$. Задайте $\\lambda$ так, чтобы $\\lambda \\approx L / 1000$.  Реализуйте в коде подсчет значения, градиента и гессиана для нашей целевой функции ($X$, $y$, $\\lambda$ лучше подавать в качестве параметра, чтобы была возможность их менять, а не только подставлять фиксированные $X_{train}$, $y_{train}$). Можно использовать как библиотеку ``numpy``, так и более специализированными библиотеки, с которыми знакомы, например, ``autograd``, ``pytorch``, ``jax``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec184b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваше решение (Code и Markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d566",
   "metadata": {},
   "source": [
    "__Задача 2. (всего 30 баллов)__ Данная часть задания связана с моментумом и ускорением.\n",
    "\n",
    "__а). (10 баллов)__ Реализуйте метод тяжелого шарика и ускоренный градиентный метод Нестерова. \n",
    "\n",
    "На всякий случай мы приводим здесь вариант описания функции для некоторого метода. Можно пользоваться таким форматом по желанию. Учтите, что в коде встречается ``x_sol`` - это проблему стоит как-то обойти или не использовать критерии, завязанные на ``x_sol``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(f, nabla_f, x_0, x_sol, gamma_k,\n",
    "                     K = 10**3, eps = 10**-5, mode = 'x_k - x^*'):\n",
    "    '''\n",
    "        f - целевая функция\n",
    "        nabla_f - градиент целевой функции\n",
    "        x_0 - стартовая точка\n",
    "        x_sol - точное решение (оно нужно для подсчета ошибки)\n",
    "        gamma_k - функция для вычисления шага метода\n",
    "        K - количество итераций (по умолчанию 1е3)\n",
    "        eps - желаемая точность (по умолчанию 1е-5)\n",
    "        mode - критерий сходимости \n",
    "               Значения либо 'x_k - x^*' - тогда критерий сходимости будет ||x_k - x^*||,\n",
    "               либо 'f(x_k) - f(x^*)' - тогда критерий сходимости будет f(x_k) - f(x^*),\n",
    "               либо 'x_k+1 - x_k', либо 'f(x_k+1) - f(x_k)' (критерии будут аналогичными)\n",
    "\n",
    "        Функция возвращает точку, в которой достигается минимум и вектор ошибок\n",
    "    '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671dfd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваше решение (Code и Markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d708445",
   "metadata": {},
   "source": [
    "__б). (20 баллов)__ Решите задачу оптимизации на тестовой выборке с помощью двух реализованных методов. Зафиксируйте шаг $\\frac{1}{L}$ и перебирайте разные значения моментума от -1 до 1 (5 хватит). Проверьте также значения моментума равные $\\frac{k}{k+3}$, $\\frac{k}{k+2}$, $\\frac{k}{k+1}$ ($k$ - номер итерации), а если целевая функция является  сильно выпуклой, то и $\\frac{\\sqrt{L} - \\sqrt{\\mu}}{\\sqrt{L} + \\sqrt{\\mu}}$. Стартовую точку и критерий сходимости можете выбрать на свой вкус, мы советуем использовать нормированную версию критерия, например, $\\frac{\\| \\nabla f(x^k) \\|}{\\| \\nabla f(x^0) \\|}$, а также использовать в Задачах 3-4 ту же самую стартовую точку и тот же самый критерий сходимости.\n",
    "\n",
    "В данном пункте нужно построить три графика: 1) значения критерия сходимости от номера итерации для метода тяжелого шарика с различными значениями моментума, 2) значения критерия сходимости от номера итерации для ускоренного градиентного метода с различными значениями моментума, 3) значения критерия сходимости от номера итерации для двух методов с наилучшим выбором моментума для каждого, а также градиентного спуска.\n",
    "\n",
    "Не забывайте делать выводы и комментировать результаты. Например, отразите всегда ли сходимость является монотонной?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee49367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваше решение (Code и Markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a4256",
   "metadata": {},
   "source": [
    "__Задача 3. (всего 40 + 30 баллов)__ Теперь поговорим про метод Ньютона и квазиньютоновские методы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc437ecf",
   "metadata": {},
   "source": [
    "__а). (20 баллов)__ Для задачи регресии реализуйте классический метод Ньютона и запустите его. Сходится ли он? Если нет, то попробуйте перед использованием метода Ньютона сначала запускать метод градиентного спуска на несколько итераций. Варьируйте количество шагов градиентного спуска. Постройте график значения критерия сходимости от номера итерации для комбинации градиентного спуска и метода Ньютона с различным числом шагов градиентного спуска. Сделайте вывод. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваше решение (Code и Markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4941f7",
   "metadata": {},
   "source": [
    "__б). (20 + 30 баллов)__ Для данной задачи реализуйте квазиньютоновский метод BFGS (можно реализовать более продвинутую версию L-BFGS, посмотрев оригинальную [статью](http://users.iems.northwestern.edu/~nocedal/PDFfiles/limited-memory.pdf) или лучше параграф 9.1 [книги](https://www.ime.unicamp.br/~pulino/MT404/TextosOnline/NocedalJ.pdf)). За реализацию L-BFGS и объяснение, как это сделать правильно и вычислительно эффективно можно получить еще __30 баллов__. Используйте метод(ы) для решения задачи регресии. Добавьте его(их) на график из предыдущего пункта. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1fbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваше решение (Code и Markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a7ed63",
   "metadata": {},
   "source": [
    "__Задача 4. (20 баллов)__ Осталось объеденить результаты полученные в Задачах 1-3. Для этого вспомним, что исходная задача регрессии является задачой машинного обучения и с помощью линейной модели $g$ можно предсказывать значения меток $y$. Как использовать итоговую модель для предсказания? Ответив на вопрос, сделайте предсказания на тестовой выборке $X_{test}$. Сравните с реальными метками $y_{test}$. Количество правильно угаданных меток есть точность/accuracy модели. Сравните метод градиентного спуска, метод тяжелого шарика, ускоренный градиентный метод, метод Ньютона, BFGS(L-BFGS). Постройте два графика: значение критерия сходимости от времени работы и точность предсказания от времени работы. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3413c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваше решение (Code и Markdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
